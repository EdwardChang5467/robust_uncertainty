{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import time\n",
    "\n",
    "def send_request(openai_model,messages):\n",
    "    sleep_time_values = (5, 10, 30, 60, 120)\n",
    "    for i in range(len(sleep_time_values)):\n",
    "        try:\n",
    "            return openai.ChatCompletion.create(\n",
    "                model=openai_model, messages=messages\n",
    "            )\n",
    "        except Exception as e:\n",
    "            sleep_time = sleep_time_values[i]\n",
    "        time.sleep(sleep_time)\n",
    "        \n",
    "    return openai.ChatCompletion.create(model=openai_model, messages=messages)\n",
    "\n",
    "claim = \"Albert Einstein was a theoretical physicist.\"\n",
    "sent = \"Albert Einstein was a German-born theoretical physicist who developed the theory of relativity and is widely regarded as one of the most influential scientists of the 20th century.\"\n",
    "gen = \"Unfortunately, I am unable to provide the Albert Einstain's information.\"\n",
    "\n",
    "CLASSFYING_PROMPT = (\n",
    "    f'''Given the problem and generation, please label the generation based on the problem, generated structure, and generated authenticity (whether there is fabricated content in the generation) (choose from FR, FT, or FF):\n",
    "1. FR: When the generated answer is a refusal, such as \"Unfortunately, I am unable to provide relevant information\" or \"Something is wrong in the question\", give the \"FR\" tag;\n",
    "2. FT: When there is no rejection answer in the generation and there are no factual errors in the generation, please provide the \"FT\" label;\n",
    "3. FF: When there is no rejection answer in the generation and there are any factual errors such as \"name error, factual error\", etc. in the generation, give the \"FF\" label.\n",
    "Please provide a label and explain the reason for providing the label. The label should be wrapped with \"[]\".\n",
    "\n",
    "[Generation]: {gen}\n",
    "[Answer]: \n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_BASE = \"https://api.lingyiwanwu.com/v1\"\n",
    "API_KEY = \"03415280c5ab4d9993b799e56443c2eb\"\n",
    "openai.api_key = API_KEY\n",
    "openai.api_base = API_BASE\n",
    "model_name = \"yi-lightning\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an intelligent assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": CLASSFYING_PROMPT},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = send_request(model_name,messages)\n",
    "reply = chat.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FR]\n",
      "\n",
      "Explanation: The generation is a refusal to provide information, as it states \"Unfortunately, I am unable to provide the Albert Einstain's information.\" Additionally, there is a misspelling of \"Einstein,\" but since the answer is a refusal and does not provide any further factual information, the primary issue is the refusal itself. Therefore, the appropriate label is \"FR.\"\n"
     ]
    }
   ],
   "source": [
    "print(reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccp_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
